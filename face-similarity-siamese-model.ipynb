{"cells":[{"cell_type":"markdown","metadata":{},"source":["## What IS Siamese network\n","\n","Siamese network is a type of neural network architecture that involves two or more identical subnetworks joined at their outputs. These subnetworks share the same parameters and weights. Siamese networks are primarily used for tasks involving similarity comparison, such as face verification, signature verification, and one-shot learning.\n","\n","Siamese networks are powerful for tasks requiring comparison and have the advantage of being efficient in learning from limited data due to their shared architecture."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T15:11:16.139301Z","iopub.status.busy":"2024-06-19T15:11:16.138829Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow==2.8.4\n","  Downloading tensorflow-2.8.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n","Collecting tensorflow-gpu==2.8.4\n","  Downloading tensorflow_gpu-2.8.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n","Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (23.5.26)\n","Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (3.10.0)\n","Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.4)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (16.0.6)\n","Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (1.26.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (3.3.0)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.8.4)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (69.0.3)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (4.9.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (1.14.1)\n","Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.4)\n","  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n","Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow==2.8.4)\n","  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.4)\n","  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (0.35.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.4) (1.60.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8.4) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4) (2.26.1)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.4)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4) (2.31.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.4)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n","Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.4)\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n","Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4) (3.0.2)\n"]}],"source":["!pip3 install tensorflow==2.8.4 tensorflow-gpu==2.8.4\n","!pip3 install cuda-python"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import random\n","import cv2 as cv\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import Model\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.utils import resample\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import save_model, load_model\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tf.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Avoid OOM errors by setting GPU Memory Consumption Growth\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus: \n","    tf.config.experimental.set_memory_growth(gpu, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["folder_name = os.listdir(\"/kaggle/input/labelled-faces-in-the-wild-lfw/lfw2\")\n","\n","imges_path = []\n","labels = []\n","\n","index = 0\n","while(index <= 100000):\n","    \n","    if(index%1000 == 0):print(index)\n","        \n","    folder_1 = random.choice(folder_name)\n","    folder_2 = random.choice(folder_name)\n","    \n","    if(folder_1 != folder_2):\n","        \n","        folder_1_ = os.listdir(f\"/kaggle/input/labelled-faces-in-the-wild-lfw/lfw2/{folder_1}\")\n","        folder_2_ = os.listdir(f\"/kaggle/input/labelled-faces-in-the-wild-lfw/lfw2/{folder_2}\")\n","        \n","        for i in folder_1_:\n","            for j in folder_2_:\n","                \n","                img_1_path = f\"/kaggle/input/labelled-faces-in-the-wild-lfw/lfw2/{folder_1}/{i}\"\n","                img_2_path = f\"/kaggle/input/labelled-faces-in-the-wild-lfw/lfw2/{folder_2}/{j}\"\n","                \n","                imges_path.append([img_1_path,img_2_path])\n","                labels.append(0)\n","                \n","                index+=1;\n","        \n","    \n","print(index)\n","print(\"----------------\") \n","index = 0\n","\n","while(index <= 100000):\n","    \n","    if(index%1000 == 0):print(index)\n","        \n","    folder_1 = random.choice(folder_name)\n","    \n","    folder_1_ = os.listdir(f\"/kaggle/input/labelled-faces-in-the-wild-lfw/lfw2/{folder_1}\")\n","\n","    for i in folder_1_:\n","        for j in folder_1_:\n","            \n","            img_1_path = f\"/kaggle/input/labelled-faces-in-the-wild-lfw/lfw2/{folder_1}/{i}\"\n","            img_2_path = f\"/kaggle/input/labelled-faces-in-the-wild-lfw/lfw2/{folder_1}/{j}\"\n","\n","            imges_path.append([img_1_path , img_2_path])\n","            labels.append(1)\n","\n","            index+=1;\n","    folder_name.remove(folder_1)\n","print(index)\n","\n","folder_name = 0"]},{"cell_type":"markdown","metadata":{},"source":["# Randomly Choose The data Index "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["size = 30000\n","\n","labels = np.array(labels)\n","zero_indices = np.where(labels == 0)[0]\n","one_indices = np.where(labels == 1)[0]\n","selected_zero_indices = np.random.choice(zero_indices, size)\n","selected_one_indices = np.random.choice(one_indices, size+2000)\n","random_numbers = np.concatenate([selected_zero_indices, selected_one_indices])"]},{"cell_type":"markdown","metadata":{},"source":["## Load images and create image pairs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["images = []\n","label = []\n","\n","for index,data in enumerate(random_numbers):\n","    if index%1000 == 0:print(index)\n","        \n","    ima_0 = cv.resize(cv.imread(imges_path[data][0]), (70, 70)) \n","    ima_1 = cv.resize(cv.imread(imges_path[data][1]), (70, 70)) \n","    \n","    #ima_0 = cv.cvtColor(ima_0, cv.COLOR_BGR2RGB)\n","    #ima_1 = cv.cvtColor(ima_1, cv.COLOR_BGR2RGB)\n","\n","    images.append([ima_0, ima_1])\n","    label.append(labels[data])\n","    \n","    \n","\n","imges_path = 0\n","random_numbers = 0\n","labels = 0\n","selected_zero_indices = 0\n","selected_one_indices = 0\n","\n","images = np.array(images)\n","label = np.array(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["unique, counts = np.unique(label, return_counts=True)\n","unique, counts"]},{"cell_type":"markdown","metadata":{},"source":["# Train Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["images,images_test,label, label_test = train_test_split(images,label,test_size=0.2,shuffle=label)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ig, axs = plt.subplots(4, 4, figsize=(5, 5))\n","\n","for i, ax in enumerate(axs.flatten()):\n","    ax.imshow(images[i][0])\n","    ax.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ig, axs = plt.subplots(4, 4, figsize=(5, 5))\n","\n","for i, ax in enumerate(axs.flatten()):\n","    ax.imshow(images_test[i][0])\n","    ax.axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Base Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_base_model(input_shape):\n","    inputs = layers.Input(shape=input_shape)\n","    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n","    x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n","    x = layers.MaxPooling2D((2,2))(x)\n","    x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n","    x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n","    x = layers.MaxPooling2D((2,2))(x)\n","    x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n","    x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n","    x = layers.MaxPooling2D((2,2))(x)\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(2048, activation='relu')(x)\n","\n","    return Model(inputs , x)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Siamese Network"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class L1Dist(layers.Layer):\n","    \n","    # Init method - inheritance\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","       \n","    # Magic happens here - similarity calculation\n","    def call(self, input_embedding, validation_embedding):\n","        return tf.math.abs(input_embedding - validation_embedding)\n","    \n","siamese_layer = L1Dist()\n","\n","def create_siamese_model(input_shape):\n","    \n","    base_model = create_base_model(input_shape)\n","    input1 = layers.Input(shape=input_shape)\n","    input2 = layers.Input(shape=input_shape)\n","    features1 = base_model(input1)\n","    features2 = base_model(input2)\n","    \n","    distance = siamese_layer(features1, features2)\n","\n","\n","    outputs = layers.Dense(1, activation='sigmoid')(distance)\n","    \n","    return Model([input1, input2], outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_shape = (70, 70, 3)\n","model = create_siamese_model(input_shape)\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{},"source":["# Model Summary"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# Callback Functions to save the Best Model "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["less_val_loss = ModelCheckpoint('/kaggle/working/best_val.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n","\n","less_train_loss = ModelCheckpoint('/kaggle/working/best_train.h5', save_best_only=True, monitor='accuracy', mode='max')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["datagen = ImageDataGenerator(rotation_range=80, \n","                             width_shift_range=0.2, \n","                             height_shift_range=0.2,\n","                             fill_mode='nearest',\n","                             horizontal_flip=True,\n","                             brightness_range=[0.2,1.5],\n","                             zoom_range=0.2,\n","                             \n","                            )"]},{"cell_type":"markdown","metadata":{},"source":["## Train The Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.fit(#[images[:,0],images[:,1]], label,\n","        datagen.flow([images[:,0],images[:,1]], label, batch_size=64),\n","        epochs=40,\n","        shuffle=True,\n","        validation_data=([images_test[:,0],images_test[:,1]], label_test),\n","        callbacks=[less_val_loss, less_train_loss])"]},{"cell_type":"markdown","metadata":{},"source":["# Save The Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save('/kaggle/working/saved_model/my_model.h5')"]},{"cell_type":"markdown","metadata":{},"source":["# Laod The Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def load_siamese_model(model_path):\n","    return load_model(model_path, custom_objects={'L1Dist': L1Dist})\n","\n","loaded_model = load_siamese_model('/kaggle/working/best_train.h5')\n","\n","# Check the loaded model\n","loaded_model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Test By Reallife Image"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image1 = cv.imread('/kaggle/input/test-img/20240409_235932-EDIT.jpg')\n","image2 = cv.imread('/kaggle/input/test-img/IMG20240306114142-EDIT.jpg')\n","\n","image1 = cv.resize(image1, (70, 70))\n","image2 = cv.resize(image2, (70, 70))\n","\n","image1 = cv.cvtColor(image1, cv.COLOR_BGR2RGB)\n","image2 = cv.cvtColor(image2, cv.COLOR_BGR2RGB)\n","\n","image1 = np.expand_dims(image1, axis=0)\n","image2 = np.expand_dims(image2, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.predict([image1,image2])[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5156211,"sourceId":8615076,"sourceType":"datasetVersion"},{"datasetId":5156254,"sourceId":8615133,"sourceType":"datasetVersion"},{"datasetId":5202792,"sourceId":8679252,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
